[
  {
    "objectID": "Example-Notebooks/lucie.html",
    "href": "Example-Notebooks/lucie.html",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "",
    "text": "Create an NCI account using institution email\nJoin below NCI projects\n\nvp91:NCI Training Project\ndk92: for environment modules and some examples\nwb00: for NCI-WeatherBench and ClimateNet datasets\nrt52: for ERA5 datasets\nob53: for BARRA2 datasets",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#cluster-access",
    "href": "Example-Notebooks/lucie.html#cluster-access",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "",
    "text": "Create an NCI account using institution email\nJoin below NCI projects\n\nvp91:NCI Training Project\ndk92: for environment modules and some examples\nwb00: for NCI-WeatherBench and ClimateNet datasets\nrt52: for ERA5 datasets\nob53: for BARRA2 datasets",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#run-the-tested-notebook",
    "href": "Example-Notebooks/lucie.html#run-the-tested-notebook",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Run the tested notebook",
    "text": "Run the tested notebook\n\nGo to ARE site, follow instructions on Run Jupyter Notebooks on Gadi page\n\nFill out the JupyterLab request form:\n\n\n\nWalltime (hours): 1\nQueue: gpuvolta\nCompute Size: 1gpu\nProject: &lt;xy01&gt;\nStorage: gdata/dk92+scratch/&lt;xy01&gt;\n\n\nClick Advanced options and fill in the following fields:\n\n\n\nModule directories: /g/data/dk92/apps/Modules/modulefiles/\n\nModules: NCI-ai-ml/25.07\n\nJobfs size: 10GB\n\n\n\nLaunch the session to run the tested notebook",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#note-on-the-tested-notebook",
    "href": "Example-Notebooks/lucie.html#note-on-the-tested-notebook",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Note on the tested notebook",
    "text": "Note on the tested notebook\nCopy the tested notebook from any/all of the following path to your own working directory. If your working directory is different from “/scratch/”, remember to change the storage directive in the JupyterLab request form.\n/g/data/dk92/notebooks/examples-aiml/lucie/data_inspection.ipynb\n/g/data/dk92/notebooks/examples-aiml/lucie/replicate_training.ipynb \n/g/data/dk92/notebooks/examples-aiml/lucie/modified_training.ipynb\n/g/data/dk92/notebooks/examples-aiml/lucie/inference_10y_rollout.ipynb\nAll the notebooks are using the original dataset released with the LUCIE paper inside their zenodo record [3]. checkpoints for models trained on Gadi is available in the directory /g/data/dk92/notebooks/examples-aiml/lucie/checkpoints together with the original checkpoint, regular_8x72_fftreg_baseline.pth, released with the LUCIE paper.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#lucie",
    "href": "Example-Notebooks/lucie.html#lucie",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "LUCIE",
    "text": "LUCIE\nLUCIE is a SFNO based atmospheric emulator that can be used for climate research. It is notable for its long-term stability in autoregressive predictions, maintaining an unbiased climatology for thousands of years. It was trained on 9.5 years of regridded ERA5 data on T30 grid, incorporating static input of orography, forcing variable of total incident solar radiation, five prognostic variables (temperature, humidity, zonal wind, meridional wind, and surface pressure), and one diagnostic variable of precipitation.\nIn the paper [1], Guan et al. demonstrate LUCIE’s ability to reproduce long-term climatology as well as its skill in subseasonal-to-seasonal scale predictions of atmospheric variables. Using 100 years of autoregressive inference with 100 ensemble members, they showcase the model’s stability and the variability of mean climatology. The ensemble outputs were further analysed to identify northern hemisphere annular mode(NAM), southern hemisphere annular mode (SAM) and the return period of extreme events.\nAt NCI, we made the environment NCI-ai-ml compatible to run LUCIE, and prepared four notebooks introducing its dataset, training and inference workflow. In addition, we extended the model to exploit the resolution-invariant property of neural operators by removing LUCIE’s positional embedding, see details in the notebook modified_training.ipynb. All the four notebooks are primarily based on their released code [2][3], which we adapted for training and inference on Gadi.\nBeyond the notebooks, we further tested multiple model architectural configurations, training datasets with different spatial resolutions and variable sets, and explored alternative training strategies. For example, results presented in the Stable Rollout section showcase a 1° model with 25 output variables, capable of generating stable rollouts at six-hour interval for up to ten years. Please note the current limitation arises from the length of our dataset, not the capability of the model.\nReferences:\n1. Guan, H., Arcomano, T., Chattopadhyay, A., & Maulik, R. (2024). LUCIE: A Lightweight Uncoupled ClImate Emulator with long-term stability and physical consistency for O(1000)-member ensembles. arXiv preprint arXiv:2405.16297. https://arxiv.org/abs/2405.16297\n\nISCLPennState. (2024). LUCIE: Lightweight Uncoupled ClImate Emulator [Software]. GitHub. https://github.com/ISCLPennState/LUCIE\nGuan, H., Arcomano, T., Chattopadhyay, A., & Maulik, R. (2025). LUCIE: A lightweight uncoupled climate emulator with long-term stability and physical consistency. Zenodo. https://doi.org/10.5281/zenodo.15164648",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#normalization-scalars",
    "href": "Example-Notebooks/lucie.html#normalization-scalars",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Normalization Scalars",
    "text": "Normalization Scalars\n\n# comparing mean, std to era5, t-&gt; t1000, q -&gt; q1000, z-&gt;z200, u-&gt; u200, v-&gt; v200\nfor var in data.files:\n    mm = data[var].mean()\n    ss = data[var].std()\n    print(f\"{var}: mean={mm}, std={ss}\")\n\ntemperature: mean=277.4626770019531, std=17.816375732421875\nhumidity: mean=0.006629979237914085, std=0.005532822106033564\nu_wind: mean=10.695755004882812, std=15.56001091003418\nv_wind: mean=-0.02342492900788784, std=12.149330139160156\nsurface_pressure: mean=96811.390625, std=9123.89453125\nprecipitation: mean=0.0006106931250542402, std=0.001604488817974925\ntisr: mean=1079093.125, std=1444145.25\norography: mean=367.17120361328125, std=809.2915649414062\n\n\n\ndata = np.load(f\"{nb_dir}/datasets/era5_T30_preprocessed.npz\")\ndata_inp = data[\"data_inp\"]     # input data \ndata_tar = data[\"data_tar\"]\nraw_means = data[\"raw_means\"]\nraw_stds = data[\"raw_stds\"]\nprog_means = raw_means[:5] # this is literally zero?\nprog_stds = raw_stds[:5] # this is literally zero?\ndiag_means = data[\"diag_means\"]\ndiag_stds = data[\"diag_stds\"]\ndiff_means = data[\"diff_means\"]\ndiff_stds = data[\"diff_stds\"]\n\n\nvars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'tisr', 'orography']\nlist(zip(vars, raw_means, raw_stds))\n\n[('temperature', np.float64(277.462646484375), np.float64(17.816408157348633)),\n ('humidity',\n  np.float64(0.006629981566220522),\n  np.float64(0.005532818380743265)),\n ('u_wind', np.float64(10.695756912231445), np.float64(15.56002426147461)),\n ('v_wind', np.float64(-0.023422522470355034), np.float64(12.14930534362793)),\n ('surface_pressure', np.float64(96811.390625), np.float64(9123.8916015625)),\n ('tisr', np.float64(1079094.75), np.float64(1444147.125)),\n ('orography', np.float64(367.17120361328125), np.float64(809.2916259765625))]\n\n\n\nvars= ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure']\nlist(zip(vars, diff_means, diff_stds))\n\n[('temperature',\n  np.float64(9.803541615838185e-05),\n  np.float64(1.4138480424880981)),\n ('humidity',\n  np.float64(2.0586108817610693e-08),\n  np.float64(0.0005922476993873715)),\n ('u_wind',\n  np.float64(-3.1180163205135614e-05),\n  np.float64(4.642238140106201)),\n ('v_wind', np.float64(-5.063314802100649e-06), np.float64(5.960874080657959)),\n ('surface_pressure',\n  np.float64(0.0021911216899752617),\n  np.float64(241.07797241210938))]\n\n\n\nlist(zip(vars,[ diff_stds[ii] / raw_stds[ii] for ii in range(5) ]))\n\n[('temperature', np.float64(0.07935651395059314)),\n ('humidity', np.float64(0.1070426785467356)),\n ('u_wind', np.float64(0.298343888293286)),\n ('v_wind', np.float64(0.4906349714705557)),\n ('surface_pressure', np.float64(0.026422713348635562))]\n\n\n\n# for log scale preciptation\ndiag_means,diag_stds\n\n(array([0.05197881]), array([0.11017133]))",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#variable-fields",
    "href": "Example-Notebooks/lucie.html#variable-fields",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Variable Fields",
    "text": "Variable Fields\n\nwdir = \"&lt;replace with the working directory&gt;\"\nraw_data = np.load(f\"{nb_dir}/datasets/era5_T30_regridded.npz\")\n\ndata = np.load(f\"{nb_dir}/datasets/era5_T30_preprocessed.npz\")\ndata_inp = data[\"data_inp\"]     # input data \ndata_tar = data[\"data_tar\"]\n\ninp_vars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'tisr', 'orography']\ntar_vars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure','precipitation']\nvars_to_plot = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'tisr', 'orography','precipitation']\n\nraw_data[\"temperature\"].shape, data_inp.shape, data_tar.shape\n\n((16538, 48, 96), (16537, 7, 48, 96), (16537, 6, 48, 96))\n\n\n\ndef img2spectrum(img,ftr):\n    npix = img.shape[-2], img.shape[-1]\n    fft_img = np.fft.fftn(img)\n    fft_amp = np.abs(fft_img)**2\n    fft_amp = fft_amp.flatten()\n\n    kfreq_x = np.fft.fftfreq(npix[1]) * npix[1] # wave vector\n    kfreq_y = np.fft.fftfreq(npix[0]) * npix[0] # wave vector\n    kfreq2D = np.meshgrid(kfreq_x, kfreq_y)\n    knrm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2)\n    knrm = knrm.flatten()\n\n    #kbins = np.arange(0.5, min(*npix)//2+1, 1.)\n    kbins = np.arange(0.5, ftr, 1.)\n    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n    Abins, _, _ = stats.binned_statistic(\n        knrm,\n        fft_amp,\n        statistic='mean',\n        bins=kbins\n    )\n\n    Abins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2)\n    return kvals, Abins\n\n\n# plot the spatial and spectral pattern of all variable fields\nfig, axes = plt.subplots(len(vars_to_plot), 3, figsize=(16, 3 * len(vars_to_plot)))\nif len(vars_to_plot) == 1:\n    axes = [axes] \n\nfor ii, var in enumerate(vars_to_plot):\n    #print(var)\n    \n    # First column: original \n    if var in inp_vars:\n        idx = inp_vars.index(var)\n        data_norm0 = data_inp[:,idx,:,:].mean(axis=(0,))\n        axes[ii, 0].pcolormesh(data_norm0)\n        axes[ii, 0].set_title(f\"normalized input {var}\")\n\n        ftr = max(*data_norm0.shape)\n        kvals0, Abins0 = img2spectrum(data_norm0,ftr)\n        axes[ii, 2].plot(kvals0, Abins0/max(Abins0), label=\"normalized input\")\n\n    # Second column: normalized input data\n    if var in tar_vars:\n        idx = tar_vars.index(var)\n        data_norm1 = data_tar[:,idx,:,:].mean(axis=(0,))\n        axes[ii, 1].pcolormesh(data_norm1)\n        axes[ii, 1].set_title(f\"normalized tar {var}\")\n\n        ftr = max(*data_norm1.shape)\n        kvals1, Abins1 = img2spectrum(data_norm1,ftr)\n        axes[ii, 2].plot(kvals1, Abins1/max(Abins1), label=\"normalized tar\")\n        \n    # third column: normalized output data\n    axes[ii, 2].legend()\n    axes[ii, 2].set_title(f\"normalized spectrum: {var}\")\n    \nplt.subplots_adjust(hspace=0.5)\n\n\n\n\n\n\n\n\n\n# plot the global mean over time of each variable\n\nfig, axes = plt.subplots(len(vars_to_plot), 3, figsize=(16, 3 * len(vars_to_plot)))\nif len(vars_to_plot) == 1:\n    axes = [axes] \n\nfor ii, var in enumerate(vars_to_plot):\n    #print(var)\n    \n    # First column: normalized input data\n    data = raw_data[var]\n    axes[ii, 0].plot(data.mean(axis=(-2,-1)))\n    axes[ii, 0].set_title(f\"original {var}\")\n\n    # Second column: normalized output data\n    if var in inp_vars:\n        idx = inp_vars.index(var)\n        data_norm0 = data_inp[:,idx,:,:].mean(axis=(-2,-1))\n        axes[ii, 1].plot(data_norm0)\n        axes[ii, 1].set_title(f\"normalized input {var}\")\n\n    # third column: normalized input vs output data spectrum\n    if var in tar_vars:\n        idx = tar_vars.index(var)\n        data_norm1 = data_tar[:,idx,:,:].mean(axis=(-2,-1))\n        axes[ii, 2].plot(data_norm1)\n        axes[ii, 2].set_title(f\"normalized tar {var}\")\n    \nplt.subplots_adjust(hspace=0.5)\n\n\n\n\n\n\n\n\n\n# plot the distribution of all variable fileds\n\nwdir = \"&lt;replace with the working directory&gt;\"\nraw_data = np.load(f\"{wdir}/era5_T30_regridded.npz\")\n\ndata = np.load(f\"{wdir}/era5_T30_preprocessed.npz\")\ndata_inp = data[\"data_inp\"]     # input data \ndata_tar = data[\"data_tar\"]\n\ninp_vars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'tisr', 'orography']\ntar_vars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure','precipitation']\nvars_to_plot = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'tisr', 'orography','precipitation']\n\nfig, axes = plt.subplots(len(vars_to_plot), 3, figsize=(16, 3 * len(vars_to_plot)))\nif len(vars_to_plot) == 1:\n    axes = [axes] \n\nfor ii, var in enumerate(vars_to_plot):\n    #print(var)\n    data = raw_data[var]\n    data = data[~np.isnan(data)]\n    # Compute min, max, 5th and 95th percentiles\n    vmin = data.min()\n    vmax = data.max()\n\n    # First column: original \n    axes[ii, 0].hist(data, bins=100,density=True)\n    axes[ii, 0].set_title(f\"original {var}: min={vmin:.2f}, max={vmax:.2f}\")\n\n    # Second column: normalized input data\n    if var in inp_vars:\n        idx = inp_vars.index(var)\n        data_norm0 = data_inp[:,idx,:,:].flatten()\n        axes[ii, 1].hist(data_norm0, bins=100, density=True)\n        axes[ii, 1].set_title(f\"normalized input {var}\")\n\n    # third column: normalized output data\n    if var in tar_vars:\n        idx = tar_vars.index(var)\n        data_norm1 = data_tar[:,idx,:,:].flatten()\n        axes[ii, 2].hist(data_norm1, bins=100, density=True)\n        axes[ii, 2].set_title(f\"normalized tar {var}\")\n    \nplt.subplots_adjust(hspace=0.5)",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#suggested-exercises",
    "href": "Example-Notebooks/lucie.html#suggested-exercises",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Suggested Exercises",
    "text": "Suggested Exercises\n\nplot the learning curve of the training: y-axis: average training loss, x-axis: epoch.\nmodify rollout_clim and true_clim to be the latitude-weighted global mean and re-run the training\ntry expand the region where the added spectral loss covers and re-run the training.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#suggested-exercises-1",
    "href": "Example-Notebooks/lucie.html#suggested-exercises-1",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Suggested Exercises",
    "text": "Suggested Exercises\n\nidentify the difference between the above model and the model used in /g/data/dk92/notebooks/examples-aiml/lucie/replicate_training.ipynb.\ncompare learning curve of this training and the one defined in /g/data/dk92/notebooks/examples-aiml/lucie/replicate_training.ipynb.\ncompare rollouts generated from this model and the one trained in /g/data/dk92/notebooks/examples-aiml/lucie/replicate_training.ipynb.\nmodify the model further to have higher embedding dimension in the feature space.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#visualize-rollout-results",
    "href": "Example-Notebooks/lucie.html#visualize-rollout-results",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Visualize Rollout Results",
    "text": "Visualize Rollout Results\n\n# prepare for visualization\ndef generate_t30_grid():\n    # T62 Gaussian grid parameters\n    nlat = 48  # Number of latitudes\n    nlon = 96  # Number of longitudes\n\n    # Gaussian latitudes and weights\n    latitudes, weights = np.polynomial.legendre.leggauss(nlat)\n    latitudes = np.arcsin(latitudes) * (180.0 / np.pi)  # Convert to degrees\n\n    # Longitudes\n    longitudes = np.linspace(0, 360, nlon, endpoint=False)\n\n    return latitudes, longitudes\n\nlat, lon = generate_t30_grid()\n\n\nvars = ['temperature', 'humidity', 'u_wind', 'v_wind', 'surface_pressure', 'precipitation']\nnvars=len(vars)\nLon, Lat = np.meshgrid(lon, lat)",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#check-the-spatial-pattern",
    "href": "Example-Notebooks/lucie.html#check-the-spatial-pattern",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Check the Spatial Pattern",
    "text": "Check the Spatial Pattern\n\n#results from Yue's checkpoint\n# path = torch.load(f'{wdir}/checkpoints/136618981.gadi-pbs/regular_training_checkpoint.pth')\n# model.load_state_dict(path)\n\n# better checkpoint\n#path = torch.load(f'{wdir}/checkpoints/137286020.gadi-pbs/lucie_205.pt')\n#path = torch.load(f'{wdir}/checkpoints/137478626.gadi-pbs/lucie_158.pt')\n#path = torch.load(f'{wdir}/checkpoints/138987659.gadi-pbs/lucie_340.pt')\n\n#model.load_state_dict(path[\"model_state_dict\"])\n\n#rollout = inference(model, rollout_step, data_inp[initial_frame_idx].unsqueeze(0).to(device), forcing.to(device), forcing_initial_idx, prog_means, prog_stds, diag_means, diag_stds, diff_stds)\n\n\n# visualize the final timestep of each ouptut var\nw,h = 12,5\nfig,axs = plt.subplots(nvars,1, figsize=(w,h*nvars),subplot_kw={'projection': ccrs.PlateCarree()},squeeze=False)\nLon, Lat = np.meshgrid(lon, lat)\nfor ii in range(nvars):\n    pcm = axs[ii,0].pcolormesh(Lon,Lat,rollout[-1,ii,:,:])\n    axs[ii,0].coastlines()\n    axs[ii,0].set_title(f\"{vars[ii]} at step {rollout.shape[0]}\")\n    fig.colorbar(pcm, ax=axs[ii])",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#check-climatology-bias",
    "href": "Example-Notebooks/lucie.html#check-climatology-bias",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Check Climatology Bias",
    "text": "Check Climatology Bias\n\n# mean clim_bias between year 1 and 10, it is expected to be different from what reported in the training \nrollout_clim = torch.mean(torch.tensor(rollout[1460:]).to(device),dim=0)\nclim_bias = torch.mean(torch.abs(rollout_clim - true_clim))\nclim_bias\n\ntensor(18.2533, device='cuda:0')\n\n\n\n# relative clim_bias by vars\nrel_clim_bias = torch.mean(torch.abs((rollout_clim - true_clim)/true_clim),dim=(-2,-1))\nlist(zip(vars,rel_clim_bias.tolist()))\n\n[('temperature', 0.0021463886369019747),\n ('humidity', 0.09310100972652435),\n ('u_wind', 2.2337892055511475),\n ('v_wind', 2.5637850761413574),\n ('surface_pressure', 0.001107409130781889),\n ('precipitation', 0.14571672677993774)]",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#compare-global-mean-over-time",
    "href": "Example-Notebooks/lucie.html#compare-global-mean-over-time",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Compare Global Mean over Time",
    "text": "Compare Global Mean over Time\n\n# Compare global mean over time [year 1, year 10]\ndata = load_data(f\"{nb_dir}/datasets/era5_T30_regridded.npz\")[...,:6]\ntrue_clim_t = np.mean(data[1460:14600], axis=(1,2))\npred = torch.tensor(rollout[1460:]).detach()\npred_clim_t = torch.mean(pred,dim=(-1,-2))\n\n\nfig,axs = plt.subplots(nvars,1, figsize=(w*3,h*nvars))\nfor ii in range(nvars):\n    pcm1 = axs[ii].plot(true_clim_t[:,ii],label=f\"targ_{vars[ii]}\")\n    pcm2 = axs[ii].plot(pred_clim_t[:,ii],label=f\"pred_{vars[ii]}\")\n    axs[ii].set_title(f\"{vars[ii]}\")\n    axs[ii].legend(loc='upper left', bbox_to_anchor=(1.003, 1),fontsize=16)",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Example-Notebooks/lucie.html#suggested-exercises-2",
    "href": "Example-Notebooks/lucie.html#suggested-exercises-2",
    "title": "Climate Weather AI/ML Model - Lucie",
    "section": "Suggested Exercises",
    "text": "Suggested Exercises\n\nCompare rollout results from both checkpoints.\n\nUse a different metric to quantify the difference between prediction and the ground truth over time.\n\nTrack the spatial pattern evolution of an individual variable field over time.\n\nRun the notebook /g/data/dk92/notebooks/examples-aiml/lucie/modified_training.ipynb and generate the 10-year inference for its model with the checkpoints nci_mod_lucie_193.pt and/or nci_mod_lucie_219.pt inside the directory /g/data/dk92/notebooks/examples-aiml/lucie/checkpoints/.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Lucie"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html",
    "href": "Getting-Started/use-jupyterlab.html",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "",
    "text": "ARE (Australian Research Environment) gives you access to NCI’s Gadi supercomputer and data collections, all from a simple, graphical interface. ARE consists of a number of applications that support your research such as Virtual Desktop, JupyterLab, Terminal, etc.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#login-to-are",
    "href": "Getting-Started/use-jupyterlab.html#login-to-are",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Login to ARE",
    "text": "Login to ARE\nOpen https://are.nci.org.au in a new tab, and log in with your NCI account, NOT email. You will see a dashboard page as shown after login. Each App will be run as an interactive session/job connected to Gadi. In this tutorial we will start a JupyterLab session.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#new-jupyterlab-session",
    "href": "Getting-Started/use-jupyterlab.html#new-jupyterlab-session",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "New JupyterLab Session",
    "text": "New JupyterLab Session\nClick on the JupyterLab tile from the Dashboard, this will open the setting page for a new Jupyter session. We will fill in circled fields next.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#basic-settings",
    "href": "Getting-Started/use-jupyterlab.html#basic-settings",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Basic Settings",
    "text": "Basic Settings\nDepending on the notebook you are running, you may need to adjust the settings. If you are attending a workshop, you should use the settings specified in the workshop. Setting form has free text input boxes. So we can copy the example values below and paste over to the form.\n\nExample settings:\n\nWalltime (hours): 3\n\nQueue: normal\n\nCompute Size: small\n\nProject: vp91\n\nStorage: gdata/vp91+scratch/vp91\n\n\n Input boxes can also be used as dropdown selection. If you need to use different NCI projects when working on your project you might find the dropdown function helpful.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#advanced-settings",
    "href": "Getting-Started/use-jupyterlab.html#advanced-settings",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Advanced Settings",
    "text": "Advanced Settings\nClick on Show advanced settings at the end of page. This will expand the form with extra fields.  We will fill in selected fields with these values: Some field names are similar, check the field names you are editing are correct.\n\nExample advanced settings:\nFill in the following fields in the Advanced Settings section:\n\nModules:\npython3/3.11.0 cuda/12.8.0\nPython or Conda virtual environment base:\n/scratch/data/vp91/Training-Venvs/intro-to-dask",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#launch-session",
    "href": "Getting-Started/use-jupyterlab.html#launch-session",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Launch Session",
    "text": "Launch Session\nMake sure the setting fields and values are filled correctly, and then click on the Launch button at the bottom of the setting page.\nNow you will see the green Session was successfully created message at the top, and Queued status is shown on the right side of the JupyterLab session block as shown below. Wait for the session to start. The wait time depends on the number of cores as well as time requested.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#open-jupyterlab",
    "href": "Getting-Started/use-jupyterlab.html#open-jupyterlab",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Open JupyterLab",
    "text": "Open JupyterLab\nOnce the requested resources are allocated, the session will start and the status will change to Running. The Jupyter path should start with the virtual environment base value used in settings, then point to /bin/jupyter.  Confirm the Jupyter path of your session is correct, and click on Open JupyterLab. This will open a new browser tab with JupyterLab interface. \nCongratulations, you are all set for the workshop!",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#unable-to-log-in",
    "href": "Getting-Started/use-jupyterlab.html#unable-to-log-in",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Unable to Log In",
    "text": "Unable to Log In\nError:Bad Request: Requested resource does not exist.\nPossible Cause: This error is often caused by issues with browser cookies or cache.\nSolution: Open another tab and log in again, or try using incognito mode.\nError:We are sorry, but something went wrong.\nPossible Cause: Exceeding the /home file system quota on Gadi.\nDiagnosis: You will be able to confirm this by executing the quota -s command on Gadi’s login node. If this is the case, see the usage of Gadi’s HOME using the du -h --max-depth=1 ~ command.\nSolution: Deleting/moving files from your Gadi’s HOME directory to keep the usage below the quota.\nError:Web application could not be started by the Phusion Passenger(R) application server...\nPossible Cause: Exceeding the /home file system quota on Gadi.\nDiagnosis: You will be able to confirm this by executing the quota -s command on Gadi’s login node. If this is the case, see the usage of Gadi’s HOME using the du -h --max-depth=1 ~ command.\nSolution: Deleting/moving files from your Gadi’s HOME directory to keep the usage below the quota.\nError:Web application could not be started by the Phusion Passenger(R) application server...\nPossible Cause: Exceeding the /home file system quota on Gadi.\nDiagnosis: You will be able to confirm this by executing the quota -s command on Gadi’s login node. If this is the case, see the usage of Gadi’s HOME using the du -h --max-depth=1 ~ command.\nSolution: Deleting/moving files from your Gadi’s HOME directory to keep the usage below the quota.\n## Unable to Launch Session Error: qsub: Error: You are not a member of project vp91. You must be a member of a project to submit a job under that project.\nPossible Cause: You are not a member of the project used, or if you recently joined the project and system is syncing account status.\nSolution: Wait for 20 minutes and try again.\nError: Failed to submit session with the following error: usage: qsub [-a date_time]… If this job failed to submit because of an invalid job name please ask your administrator to configure OnDemand to set the environment variable OOD_JOB_NAME_ILLEGAL_CHARS.\nPossible Cause: Special characters are submitted into the setting form.\nSolution: Check the setting page values or manually type the values into the form.\nError:Disk quota exceeded @ dir_s_mkdir - /home/&lt;institution_code&gt;/&lt;username&gt;/ondemand/data/sys/dashboard/batch_connect/sys/desktop_vnc/ncigadi/output/&lt;session_ID&gt;\nPossible Cause: Exceeding the /home file system quota on Gadi.\nDiagnosis: You will be able to confirm this by executing the quota -s command on Gadi’s login node. If this is the case, see the usage of Gadi’s HOME using the du -h --max-depth=1 ~ command.\nSolution: Deleting/moving files from your Gadi’s HOME directory to keep the usage below the quota.\nError: unix listener: cannot bind to path /home/&lt;institution_code&gt;/&lt;username&gt;/.ssh/&lt;session_ID&gt;: No such file or directory. Your connection to the remote server has been terminated. Possible Cause: SSH folder is not properly setup in your account. Diagnosis: You will be able to confirm this by executing the ls -lah ~ command on Gadi’s login node. If there is no .ssh in the output or the folder permission is not correct, follow below steps to resolve the issue. Solution: 1. Login to Gadi terminal 2. Execute the following commands:\n2. **mkdir -p ~/.ssh**\n2. **chmod 700 ~/.ssh**",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#check-debug-log-for-other-issues",
    "href": "Getting-Started/use-jupyterlab.html#check-debug-log-for-other-issues",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Check Debug Log for Other Issues",
    "text": "Check Debug Log for Other Issues\nIf your issue is not solved above, please follow these instructions to check the session log or report the issue: 1. Go to my interactive sessions by clicking one of the buttons on the page: \n\nOn the Session block, click Debug Log link  ## Report Issue to Helpdesk\nCopy Debug Log link (if job is still running then use the Session id link).\nSend a new email to help@nci.org.au, include:\n\nSubject: “ARE” and short description of issue\nBody:\n\nA more detailed issue description.\nDebug Log/Session id Link: The link you copied.\nOperating System: e.g. Windows 11, MacOSX 13, Debian Linux etc.\nBrowser: e.g. Firefox 102, Chrome 103, Edge 103\nConnection: e.g. Wired network at ANU, Wireless at Home etc.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#interface",
    "href": "Getting-Started/use-jupyterlab.html#interface",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Interface",
    "text": "Interface\nThe JupyterLab workspace consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar.\nThe left sidebar contains a file browser, the list of running kernels and terminals, the Dask extension of JupyterLab, Table of Contentions and Extension Manager.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#running-notebook",
    "href": "Getting-Started/use-jupyterlab.html#running-notebook",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Running Notebook",
    "text": "Running Notebook\nDouble-click on a notebook (.ipynb) file to open it in the main area. Selected cell is highlighted in blue. Run Selected Cell\nPress: Shift + Enter or Click: the run button on toolbar",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/use-jupyterlab.html#server-connection-error",
    "href": "Getting-Started/use-jupyterlab.html#server-connection-error",
    "title": "Run Jupyter Notebooks on Gadi",
    "section": "Server Connection Error",
    "text": "Server Connection Error\nError:\"Server Connection Error. A connection to the Jupyter server could not be established. JupyterLab will continue trying to reconnect. Check your network connection or Jupyter server configuration.\" Possible Cause: Reached requested job Walltime or exceeding requested JOBFS size. Diagnosis: You will be able to confirm this by checking session log file:$HOME/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/ncigadi/output/&lt;session_ID&gt;/output.logon Gadi. Solution: Re-launching the JupyterLab session by either requesting more Walltime or JOBFS (available under the “Advanced options …”), based on the cause of the issue. ## Saving File Error\nError: \"Unexpected error while saving file: … [Errno 13] Permission denied: '…' \" Possible Cause: This error occurs when a file with the same name already exists and might be owned by another user. Diagnosis: Check the file directory on the left panel of JupyterLab page that you are saving the file in your own folder, not other users. Suggestion: Rename the file and try saving it again.",
    "crumbs": [
      "Getting Started",
      "Run Jupyter Notebooks on Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/filetransfer.html",
    "href": "Getting-Started/filetransfer.html",
    "title": "File Transfer",
    "section": "",
    "text": "File transfer should be done using Gadi’s data-mover nodes (domain name ‘gadi-dm.nci.org.au’), which are dedicated for moving data to and from the system at a high speed.\n\n\n\n\n\n\n\n\nOperating System\nProgram\nDescription\n\n\n\n\nMac and Linux\nrsync\nA powerful tool for transferring large files, with the ability to compare source and destination and only send changes.\n\n\nMac and Linux\nscp\nA simple file transfer tool (secure copy).\n\n\nWindows\nWinSCP\nA graphical interface for transferring files.\n\n\n\n\nNote: Transferring Code\nThe best way to transfer code from one computer to another is to host the code in a source code repository using a &gt; versioning system such as git and clone the repository to the supercomputer. Recommended learning: Version Control with Git",
    "crumbs": [
      "Getting Started",
      "File Transfer"
    ]
  },
  {
    "objectID": "Getting-Started/filetransfer.html#from-local-system-gadi",
    "href": "Getting-Started/filetransfer.html#from-local-system-gadi",
    "title": "File Transfer",
    "section": "From local system → Gadi",
    "text": "From local system → Gadi\nTo start a scp transfer through Gadi’s data-mover nodes, you can run the command,\n$ scp &lt;source&gt; &lt;destination&gt;\nNotice that the domain is gadi-dm.nci.org.au, as you are logging into a data-mover node instead of a login node.\nReplace the filename with the file you wish to transfer, including the file extension e.g. .sh, .pdf, and use your username as the login. The destination should be replaced with location that you want the file to be placed in, like the following for an example:\n$ scp testfile.sh &lt;user&gt;@gadi-dm.nci.org.au:/scratch/&lt;project dir&gt;/&lt;somewhere&gt;/\nYou will then be prompted for your password, once entered, your file transfer will begin.",
    "crumbs": [
      "Getting Started",
      "File Transfer"
    ]
  },
  {
    "objectID": "Getting-Started/filetransfer.html#from-gadi-local-system",
    "href": "Getting-Started/filetransfer.html#from-gadi-local-system",
    "title": "File Transfer",
    "section": "From Gadi → local system",
    "text": "From Gadi → local system\nIf you want to do the opposite, move a file from Gadi to your local system, you simply need to reverse the prompt to reflect this, like so\n$ scp &lt;user&gt;@gadi-dm.nci.org.au:/scratch/&lt;project dir&gt;/&lt;somewhere&gt;/ ./\nTo find a listing of all the options available to you with scp, e.g. which option to use to transfer a folder/directory, use the command\n$ man scp",
    "crumbs": [
      "Getting Started",
      "File Transfer"
    ]
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Self-paced Courses",
    "section": "",
    "text": "E-research community and NCI training courses are available here.\n\nProgramming Basics\nVersion Control with Git\nIntroduction to Python\nIntroduction to the Unix Shell\nC Programming for Scientific Computing\n\n\nDeep Learning\nIntroduction to Neural Networks and PyTorch\nDeep Learning Model Development in Weather and Climate Studies\n* Lucie Notebook\n\n\nHigh Performance Computing\nHands-on with Gadi\nHPC 101 Series\n\n\nParallel Programming\nIntroduction to Parallel Programming using Python\nParallel Python Introduction to Dask\nParallel Python Introduction to Numba\nParallel Python Introduction to CuPy\nGPU Programming Introduction to CUDA\nParallel Programming Introduction to MPI\n\n\nGenAI/LLM",
    "crumbs": [
      "Self-paced Courses"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Training Resources",
    "section": "",
    "text": "Workshops, tutorials, and learning resources for Australian researchers.\nTo learn more about Gadi visit https://opus.nci.org.au/x/4gD."
  },
  {
    "objectID": "Getting-Started/accounts.html",
    "href": "Getting-Started/accounts.html",
    "title": "Accounts",
    "section": "",
    "text": "New and existing NCI users with stakeholder affiliation can register for an account or new project at our MyNCI portal.\nLead Chief Investigators can register a new project, and the Scheme Manager for the nominated allocation scheme will receive the new proposal in email. The Scheme Manager will review and decide if the proposal will be approved.\nProspective stakeholders can register interest in obtaining NCI services via NCI user support at help@nci.org.au. Please include contact details and a basic description of your requirements in your enquiry email.\n\nAccess Scheme\nNational Computational Merit Allocation Scheme The National Computational Merit Allocation Scheme (NCMAS) provides researchers with annual access to Australia’s major national computational facilities, namely NCI and the Pawsey Supercomputing Research Centre, through a merit-based selection process. In total, NCMAS distributes around 700 million units of computing time to meritorious applicants from around Australia. The main call for applications is made annually in August-October to determine allocations for the following calendar year. Information and application materials are available through the NCMAS portal.\nOther access schemes and methods can be found here.\nNote that your account needs to be linked to a project to access NCI resources. Resources at NCI are allocated to projects and not to individual users.\n\n\nCreate User Account\n\nGo to https://my.nci.org.au/mancini\n\nClick on the Sign up here link and complete the registration form. Note: you must provide a current institutional email address (Gmail, Hotmail, etc are not accepted). Mobile phone number is strongly encouraged to easily reset your password.\n\nSelect the option to join an existing project or propose a new project at Step 3 of the form. Note: A new project proposal to be assessed by a Scheme Manager to determine if they will grant your project time.\n\nClick “Finish” on the final page of the form to complete your registration request.\n\nYour username will become active when a project Lead CI approves your request to join their project, or when a Scheme Manager approves your new project proposal. You will receive a confirmation email.",
    "crumbs": [
      "Getting Started",
      "Accounts"
    ]
  },
  {
    "objectID": "Getting-Started/logingadi.html",
    "href": "Getting-Started/logingadi.html",
    "title": "Login to Gadi",
    "section": "",
    "text": "Access to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\nFor security reasons we ask that you avoid setting up passwordless ssh to Gadi. Entering your password every time you login is more secure, or using specialised ssh secure agents.",
    "crumbs": [
      "Getting Started",
      "Login to Gadi"
    ]
  },
  {
    "objectID": "Getting-Started/logingadi.html#introduction-to-the-unix-shell",
    "href": "Getting-Started/logingadi.html#introduction-to-the-unix-shell",
    "title": "Login to Gadi",
    "section": "Introduction to the Unix Shell",
    "text": "Introduction to the Unix Shell",
    "crumbs": [
      "Getting Started",
      "Login to Gadi"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html",
    "href": "Example-Notebooks/aardvark.html",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "",
    "text": "Create an NCI account using institution email\nJoin below NCI projects\n\nvp91:NCI Training Project\ndk92: for environment modules and some examples\nwb00: for NCI-WeatherBench and ClimateNet datasets\nrt52: for ERA5 datasets\nob53: for BARRA2 datasets",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#cluster-access",
    "href": "Example-Notebooks/aardvark.html#cluster-access",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "",
    "text": "Create an NCI account using institution email\nJoin below NCI projects\n\nvp91:NCI Training Project\ndk92: for environment modules and some examples\nwb00: for NCI-WeatherBench and ClimateNet datasets\nrt52: for ERA5 datasets\nob53: for BARRA2 datasets",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#run-the-tested-notebook",
    "href": "Example-Notebooks/aardvark.html#run-the-tested-notebook",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Run the tested notebook",
    "text": "Run the tested notebook\n\nGo to ARE site, follow instructions on Run Jupyter Notebooks on Gadi page\n\nFill out the JupyterLab request form:\n\n\n\nWalltime (hours): 1\nQueue: gpuvolta\nCompute Size: 1gpu\nProject: &lt;xy01&gt;\nStorage: gdata/dk92+scratch/&lt;xy01&gt;\n\n\nClick Advanced options and fill in the following fields:\n\n\n\nModule directories: /g/data/dk92/apps/Modules/modulefiles/\n\nModules: NCI-ai-ml/25.07\n\nJobfs size: 10GB\n\n\n\nLaunch the session to run the tested notebook",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#note-on-the-tested-notebook",
    "href": "Example-Notebooks/aardvark.html#note-on-the-tested-notebook",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Note on the tested notebook",
    "text": "Note on the tested notebook\ncopy the tested notebook from any/all of the following path to your own working directory. If your working directory is different from “/scratch/”, remember to change the storage directive in the JupyterLab request form.\n/g/data/dk92/notebooks/examples-aiml/aardvark-weather/data_demo.ipynb\n/g/data/dk92/notebooks/examples-aiml/aardvark-weather/forecast_demo.ipynb\n/g/data/dk92/notebooks/examples-aiml/aardvark-weather/e2e_finetune_demo.ipynb\n/g/data/dk92/notebooks/examples-aiml/aardvark-weather/train_encoder.ipynb\n\nall the notebooks are using the original datasets released with the Aardvark-Weather paper[1] in its huggingface record[3].\nTo run inference only, the dataset is downloaded to /g/data/dk92/data/aardvark-weather/sample_data.\nTo train the encoder, user has to do the data transformation from the training dataset /g/data/dk92/data/aardvark-weather/training_data since the default data loader doesn’t read directly from the netcdf files in the training datasets. The transformed data requires approximately 200GiB disk space. If you need help to do the data transformation, please get in touch through NCI help desk.\nthe original four checkpoints, for the encoder, processor, decoder and the end-to-end model, were downloaded from the huggingface record[3] and hosted in g/data/dk92/data/aardvark-weather/trained_model.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#aardvark-weather",
    "href": "Example-Notebooks/aardvark.html#aardvark-weather",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Aardvark Weather",
    "text": "Aardvark Weather\nAardvark Weather is an end-to-end data-driven model for weather prediction. Unlike most of its data-driven forecasting model peers, it directly maps past observations to future forecasts. The architecture consists of three components: an encoder, a processor, and a decoder. The encoder ingests raw observations to estimate the gridded initial state of the atmosphere. The processor then advances the estimated atmospheric state in time. Finally, the decoder generates the prediction at the point of interest based on the gridded state forecast. Each component was initially trained independently. The encoder was trained on level 1B or 1C satellite data (ASCAT, AMSU-A & B, HIRS, IASI, GRIDSAT) and in-situ records (HadISD, ICOADS, IGRA). The processor was trained on 1.5° regridded ERA5 dataset utilising surface variables (t2m, u10, v10, mslp) and pressure level variables (q, z, t, u, v) at level 200, 500, 700, and 850 hPa. The decoder was trained on HadISD station data using near-surface temperature (t2m) and wind speed (ws). Once these blocks were individually trained, they were chained in sequence and fine-tuning into the end-to-end model.\nIn the paper [1] , the authors systematically benchmark Aardvark Weather and demonstrate its potential to replace the full numerical weather prediction (NWP) pipeline.\nFor global gridded forecasts, Aardvark achieves latitude-weighed RMSE comparable to the Integrated Forecasting System (IFS) in its high resolution configuration (HRES) from the European Centre for Medium-Range Weather Forecasts (ECMWF) and Global Forecast System (GFS) from the National Centers for Environmental Prediction, across variables including t2m, u10, v10, mslp, t850, u700, and q700 at lead time up to 10 days. Spatially, the model successfully reproduces the large-scale atmospheric state features in both the mid-latitude and the tropics.\nFor station forecasting, Aardvark delivers global mean absolute error (MAE) on par with the station-corrected HRES for temperatures predictions up to 10 days and for wind speed up to 6 days. Notably, in resource-limited areas such as West Africa and the Pacific, Aardvark consistently out-performed the station-corrected IFS-HRES across all lead times.\nAt NCI, we configured the NCI-ai-ml environment compatible to support Aardvark Weather [2], enabling researchers to explore its datasets, and building its training and inference pipelines on Gadi. To assist users, four Jupyter notebooks have been developed, showcasing the satellite and synoptic observation datasets[3], model training workflow, and forecast evaluation procedures.\nReference:\n1. Allen, A., Markou, S., Tebbutt, W. et al. (2025). End-to-end data-driven weather prediction. Nature, 641, 1172–1179. https://doi.org/10.1038/s41586-025-08897-0\n\nAllen, A. (2025). aardvark-weather-public [Software]. GitHub. https://github.com/anna-allen/aardvark-weather-public\nAardvark Weather Observational Dataset, av555/aardvark-weather, Hugging Face, doi:10.57967/hf/4274, https://huggingface.co/datasets/av555/aardvark-weather”",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#data",
    "href": "Example-Notebooks/aardvark.html#data",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Data",
    "text": "Data\nOpen a sample of data required to produce a forecast.\n\nwith open(f\"{ddir}/sample_data/sample_data_final.pkl\", 'rb') as fp:\n    data = pickle.load(fp)\n\n\n[ ki for ki in data[\"assimilation\"].keys() if \"_x_current\" in ki]\n\n['sat_x_current',\n 'icoads_x_current',\n 'igra_x_current',\n 'amsua_x_current',\n 'amsub_x_current',\n 'iasi_x_current',\n 'ascat_x_current',\n 'hirs_x_current',\n 'era5_x_current']\n\n\nMultiple different datasets are utilised as input to create a forecast, each with multiple channels including observations and metadata. Example channels for each of these are plotted below. The plot_channel variable in each cell can be adjusted to visualise different channels.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#satellite",
    "href": "Example-Notebooks/aardvark.html#satellite",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Satellite",
    "text": "Satellite\nFirst visualise the satellite data from HIRS, AMSU-A, AMSU-B, IASI and ASCAT\n\n# Set up longitude and latitude for plotting\nlon = np.linspace(0,359,360)\nlat = np.linspace(90,-90,181)\n\nlon_1p5 = np.linspace(0,359,240)\nlat_1p5 = np.linspace(90,-90,121)\n\n\nHIRS\n\nfig = plt.figure()\nplot_channel = 11\np = plt.contourf(\n    lon,\n    lat,\n    data[\"assimilation\"][\"hirs_current\"][0,...,plot_channel].cpu().T, \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"HIRS channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAMSU-A\n\nfig = plt.figure()\nplot_channel = 8\np = plt.contourf(\n    lon, \n    lat[:-1],\n    data[\"assimilation\"][\"amsua_current\"][0,...,plot_channel].cpu(), \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"AMSU-A channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAMSU-B\n\nfig = plt.figure()\nplot_channel = 10\np = plt.contourf(\n    lon,\n    lat,\n    data[\"assimilation\"][\"amsub_current\"][0,...,plot_channel].T.cpu(), \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"AMSU-A channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIASI\n\nfig = plt.figure()\nplot_channel = 10\np = plt.contourf(\n    lon,\n    lat,\n    data[\"assimilation\"][\"iasi_current\"][0,...,plot_channel].T.cpu(), \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"IASI channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nASCAT\n\nprint(f\"There are {data['assimilation']['ascat_current'].shape[-1]} channels in this dataset.\\nPlotting channel 5.\\nModify plot_channel to any integer between 0 and 16 to inspect other channels.\")\n\nfig = plt.figure()\nplot_channel = 5\np = plt.contourf(\n    lon,\n    lat,\n    data[\"assimilation\"][\"ascat_current\"][0,...,plot_channel].T.cpu(), \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"ASCAT channel {plot_channel}\")\nplt.show()\n\nThere are 17 channels in this dataset.\nPlotting channel 5.\nModify plot_channel to any integer between 0 and 16 to inspect other channels.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#gridsat",
    "href": "Example-Notebooks/aardvark.html#gridsat",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "GRIDSAT",
    "text": "GRIDSAT\nNOTE from NCI: Two channels of GRIDSAT dataset are also used in training of Aardvark Weather.\n\nnc_file = f\"{ddir}/training_data/gridsat_data_v1.nc\"  \nnc = xr.open_dataset(nc_file)\nnc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:       (time: 4746, latitude: 200, longitude: 514)\nCoordinates:\n  * time          (time) datetime64[ns] 38kB 2007-01-02 ... 2019-12-30\n  * longitude     (longitude) float32 2kB 0.215 0.915 1.615 ... 358.8 359.5\n  * latitude      (latitude) float32 800B -69.68 -68.99 -68.28 ... 68.92 69.61\nData variables:\n    gridsat_6p7   (time, latitude, longitude) float32 2GB ...\n    gridsat_10p3  (time, latitude, longitude) float32 2GB ...xarray.DatasetDimensions:time: 4746latitude: 200longitude: 514Coordinates: (3)time(time)datetime64[ns]2007-01-02 ... 2019-12-30array(['2007-01-02T00:00:00.000000000', '2007-01-03T00:00:00.000000000',\n       '2007-01-04T00:00:00.000000000', ..., '2019-12-28T00:00:00.000000000',\n       '2019-12-29T00:00:00.000000000', '2019-12-30T00:00:00.000000000'],\n      dtype='datetime64[ns]')longitude(longitude)float320.215 0.915 1.615 ... 358.8 359.5units :degreesarray([2.149963e-01, 9.150085e-01, 1.614990e+00, ..., 3.581150e+02,\n       3.588150e+02, 3.595150e+02], dtype=float32)latitude(latitude)float32-69.68 -68.99 ... 68.92 69.61units :degreesarray([-69.685   , -68.985   , -68.284996, -67.58501 , -66.884995, -66.185   ,\n       -65.485   , -64.784996, -64.08501 , -63.385002, -62.684998, -61.984997,\n       -61.284996, -60.585003, -59.885002, -59.184998, -58.484997, -57.784996,\n       -57.085003, -56.385002, -55.685005, -54.984997, -54.284996, -53.585   ,\n       -52.885002, -52.185005, -51.484997, -50.785   , -50.085   , -49.385002,\n       -48.685   , -47.984997, -47.285   , -46.585   , -45.885002, -45.185   ,\n       -44.484997, -43.785   , -43.085   , -42.385002, -41.685   , -40.984997,\n       -40.285   , -39.585   , -38.885002, -38.185   , -37.484997, -36.785   ,\n       -36.085   , -35.385002, -34.684998, -33.984997, -33.285   , -32.585   ,\n       -31.885   , -31.185001, -30.484997, -29.785   , -29.084997, -28.385   ,\n       -27.685001, -26.985   , -26.285   , -25.585   , -24.885   , -24.185001,\n       -23.485   , -22.785   , -22.085   , -21.385   , -20.685001, -19.985   ,\n       -19.285   , -18.585   , -17.885   , -17.185001, -16.484999, -15.785001,\n       -15.084999, -14.385   , -13.684999, -12.985001, -12.285   , -11.584999,\n       -10.885   , -10.184999,  -9.485   ,  -8.785   ,  -8.084999,  -7.385   ,\n        -6.685   ,  -5.984999,  -5.285   ,  -4.585001,  -3.884998,  -3.185001,\n        -2.484998,  -1.785   ,  -1.085001,  -0.384998,   0.314999,   1.015002,\n         1.715   ,   2.414999,   3.115002,   3.814999,   4.515002,   5.215   ,\n         5.914999,   6.615002,   7.314999,   8.015001,   8.715   ,   9.414999,\n        10.115002,  10.814999,  11.515001,  12.215   ,  12.914999,  13.615003,\n        14.315   ,  15.015001,  15.714999,  16.414999,  17.115002,  17.814999,\n        18.515001,  19.215   ,  19.914999,  20.615002,  21.314999,  22.015001,\n        22.715   ,  23.414999,  24.115002,  24.814999,  25.515001,  26.215   ,\n        26.914999,  27.615002,  28.314999,  29.015003,  29.715   ,  30.414999,\n        31.115002,  31.814999,  32.515003,  33.215   ,  33.915   ,  34.615   ,\n        35.315   ,  36.015003,  36.715   ,  37.415   ,  38.115   ,  38.815   ,\n        39.515003,  40.215   ,  40.915   ,  41.615   ,  42.315   ,  43.015003,\n        43.715   ,  44.415   ,  45.115   ,  45.815   ,  46.515003,  47.215   ,\n        47.915   ,  48.615   ,  49.315   ,  50.015003,  50.715   ,  51.415   ,\n        52.115   ,  52.814995,  53.515003,  54.215004,  54.915   ,  55.615   ,\n        56.314995,  57.015003,  57.715004,  58.415   ,  59.114998,  59.815002,\n        60.515003,  61.215004,  61.915   ,  62.614998,  63.315002,  64.015   ,\n        64.715004,  65.415   ,  66.115   ,  66.815   ,  67.515   ,  68.215004,\n        68.915   ,  69.615   ], dtype=float32)Data variables: (2)gridsat_6p7(time, latitude, longitude)float32...units :K[487888800 values with dtype=float32]gridsat_10p3(time, latitude, longitude)float32...units :K[487888800 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2007-01-02', '2007-01-03', '2007-01-04', '2007-01-05',\n               '2007-01-06', '2007-01-07', '2007-01-08', '2007-01-09',\n               '2007-01-10', '2007-01-11',\n               ...\n               '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24',\n               '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28',\n               '2019-12-29', '2019-12-30'],\n              dtype='datetime64[ns]', name='time', length=4746, freq=None))longitudePandasIndexPandasIndex(Index([ 0.214996337890625,  0.915008544921875,     1.614990234375,\n         2.31500244140625,    3.0150146484375,  3.714996337890625,\n        4.415008544921875,     5.114990234375,   5.81500244140625,\n          6.5150146484375,\n       ...\n        353.2149963378906,  353.9150085449219,   354.614990234375,\n       355.31500244140625,  356.0150146484375,  356.7149963378906,\n        357.4150085449219,   358.114990234375, 358.81500244140625,\n        359.5150146484375],\n      dtype='float32', name='longitude', length=514))latitudePandasIndexPandasIndex(Index([-69.68499755859375, -68.98500061035156, -68.28499603271484,\n       -67.58500671386719, -66.88499450683594, -66.18499755859375,\n       -65.48500061035156, -64.78499603271484, -64.08500671386719,\n       -63.38500213623047,\n       ...\n        63.31500244140625,  64.01499938964844,  64.71500396728516,\n        65.41500091552734,  66.11499786376953,  66.81500244140625,\n        67.51499938964844,  68.21500396728516,  68.91500091552734,\n        69.61499786376953],\n      dtype='float32', name='latitude', length=200))Attributes: (0)\n\n\n\nlat_sat =nc.latitude.values\nlon_sat =nc.longitude.values\ndata_sat= nc[\"gridsat_6p7\"].values\n\nprint(f\"There are 2 channels in this dataset.\\nPlotting channel `gridsat_6p7`.\\nModify the varname used in data_sat to inspect the other channel `gridsat_10p3`.\")\n\nfig = plt.figure()\np = plt.contourf(\n    lon_sat,\n    lat_sat,\n    data_sat[0,:], \n    levels=100,\n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised radiance') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"GRIDSAT channel 6p7\")\nplt.show()\n\nThere are 2 channels in this dataset.\nPlotting channel `gridsat_6p7`.\nModify the varname used in data_sat to inspect the other channel `gridsat_10p3`.",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#synops",
    "href": "Example-Notebooks/aardvark.html#synops",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "SYNOPS",
    "text": "SYNOPS\nWe next visualise the SYNOPS data from land stations, marine platforms and radiosonde profiles\n\nHadISD\n\nfig = plt.figure()\nplot_channel = 0\np = plt.scatter(\n    data[\"assimilation\"][\"x_context_hadisd_current\"][plot_channel][0,0,:].cpu(),\n    data[\"assimilation\"][\"x_context_hadisd_current\"][plot_channel][0,1,:].cpu(),\n    c = data[\"assimilation\"][\"y_context_hadisd_current\"][plot_channel][0,:].cpu(), \n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised value') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"HadISD channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nICOADS\n\nplot_channel = 1\nfig = plt.figure()\np = plt.scatter(\n    data[\"assimilation\"][\"icoads_x_current\"][0][0,:].cpu(),\n    data[\"assimilation\"][\"icoads_x_current\"][1][0,:].cpu(),\n    c = data[\"assimilation\"][\"icoads_current\"][0,plot_channel,:].cpu(), \n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised value') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"ICOADS channel {plot_channel}\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIGRA\n\nplot_channel = 1\nfig = plt.figure()\np = plt.scatter(\n    data[\"assimilation\"][\"igra_x_current\"][0][0,:].cpu(),\n    data[\"assimilation\"][\"igra_x_current\"][1][0,:].cpu(),\n    c = data[\"assimilation\"][\"igra_current\"][0,plot_channel,:].cpu(), \n    cmap=\"magma\")\ncbar = fig.colorbar(p)\ncbar.set_label('Normalised value') \nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"IGRA channel {plot_channel}\")\nplt.show()",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#generate-predictions",
    "href": "Example-Notebooks/aardvark.html#generate-predictions",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Generate predictions",
    "text": "Generate predictions\nLoad the sample data (for a detailed analysis and visualisation of the contents of this dataset see data_demo.ipynb)\n\nwith open(f\"{ddir}/sample_data/sample_data_final.pkl\", \"rb\") as fp:\n    data = pickle.load(fp)\n\nLoad the model to generate predictions at one day leadtime. First select which varaible to generate station forecasts for.\n\nlocal_forecast_var = \"tas\"  # Model weights included for windspeed (ws) and 2tm (tas)\n\nmodel = ConvCNPWeatherE2E(\n    device=device,\n    lead_time=1,\n    se_model_path=f\"{ddir}/trained_model/encoder\",\n    forecast_model_path=f\"{ddir}/trained_model/processor\",\n    sf_model_path=f\"{ddir}/trained_model/decoder/{local_forecast_var}/\",\n    return_gridded=True,\n    aux_data_path=f\"{ddir}/sample_data/\",\n)\n\nRun the model to generate a forecast the sample data. This outputs the station forecast, gridded forevast and initial state\n\nstation_forecast, global_forecast, initial_state = model(data)\n\nafter rMLP: torch.Size([1, 8719, 1])\n\n\n\nglobal_forecast.shape\n\ntorch.Size([1, 121, 240, 24])\n\n\n\nstation_forecast.shape\n\ntorch.Size([1, 8719])",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#visualise-model-predictions",
    "href": "Example-Notebooks/aardvark.html#visualise-model-predictions",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Visualise model predictions",
    "text": "Visualise model predictions\nFirst look at the gridded forecasts. Visualise several variables\n\nvars = [\n    \"u10\",\n    \"v10\",\n    \"t2m\",\n    \"mslp\",\n    \"z200\",\n    \"z500\",\n    \"z700\",\n    \"z850\",\n    \"q200\",\n    \"q500\",\n    \"q700\",\n    \"q850\",\n    \"t200\",\n    \"t500\",\n    \"t700\",\n    \"t850\",\n    \"u200\",\n    \"u500\",\n    \"u700\",\n    \"u850\",\n    \"v200\",\n    \"v500\",\n    \"v700\",\n    \"v850\",\n]\n\nvar_index_mapping = {k: v for v, k in enumerate(vars)}\n\n\nlon = np.linspace(0, 359, 240)\nlat = np.linspace(-90, 90, 121)\n\nSelect the variable and data to plot. To plot another variable simply change the variable argument below.\n\nvariable = \"u10\"\nvar_index = var_index_mapping[variable]\ninitial_state_var = initial_state[0, ..., var_index].detach().cpu().numpy()\nglobal_forecast_var = global_forecast[0, ..., var_index].detach().cpu().numpy()\ncolorscale_mag = np.max(np.abs(initial_state_var))\n\nPlot the initial state\n\nfig = plt.figure(figsize=(10, 5))\nplot_channel = 10\np = plt.contourf(\n    lon,\n    lat,\n    initial_state_var,\n    levels=100,\n    vmax=colorscale_mag,\n    vmin=-colorscale_mag,\n    cmap=\"RdBu_r\",\n)\ncbar = fig.colorbar(p)\n# cbar.set_label('(m/s)')\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"{variable} initial state\")\nplt.show()\n\n\n\n\n\n\n\n\nPlot the prediction at one day leadtime\n\nfig = plt.figure(figsize=(10, 5))\nplot_channel = 10\np = plt.contourf(\n    lon,\n    lat,\n    global_forecast_var,\n    levels=100,\n    vmax=colorscale_mag,\n    vmin=-colorscale_mag,\n    cmap=\"RdBu_r\",\n)\ncbar = fig.colorbar(p)\n# cbar.set_label('(m/s)')\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"{variable} forecast\")\nplt.show()\n\n\n\n\n\n\n\n\nThe model also returns the station forecasts for T2M\n\nSTATION_LON_LAT_SF = 360\nHADISD_SCALING_FACTOR = 10\n# Factors to unnormalise predictions\nmean = np.load(f\"{ddir}/sample_data/norm_factors/mean_hadisd_{local_forecast_var}.npy\")\nstd = np.load(f\"{ddir}/sample_data/norm_factors/std_hadisd_{local_forecast_var}.npy\")\n\n\nstation_forecast = (\n    station_forecast.detach().cpu() * std + mean\n) * HADISD_SCALING_FACTOR\n\n/jobfs/151106967.gadi-pbs/ipykernel_405486/3168040627.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n  station_forecast.detach().cpu() * std + mean\n\n\n\nfig = plt.figure(figsize=(10, 5))\nplot_channel = 10\np = plt.scatter(\n    data[\"downscaling\"][\"x_target\"][0, 0, :].detach().cpu() * STATION_LON_LAT_SF,\n    data[\"downscaling\"][\"x_target\"][0, 1, :].detach().cpu() * STATION_LON_LAT_SF,\n    c=station_forecast[0, :],\n    vmax=30,\n    vmin=-30,\n    cmap=\"RdBu_r\",\n)\ncbar = fig.colorbar(p)\ncbar.set_label(\"(C)\")\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"{local_forecast_var}\")\nplt.show()",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#generate-predictions-1",
    "href": "Example-Notebooks/aardvark.html#generate-predictions-1",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Generate predictions",
    "text": "Generate predictions\nLoad the sample data (for a detailed analysis and visualisation of the contents of this dataset see data_demo.ipynb)\n\nwith open(f'{ddir}/sample_data/sample_data_final.pkl', 'rb') as fp:\n    data = pickle.load(fp)\n\nLoad the end to end model. First select which varaible to generate station forecasts for.\n\nlocal_forecast_var = \"tas\" # Model weights included for windspeed (ws) and 2tm (tas)\n\nmodel = ConvCNPWeatherE2E(\n    device=\"cuda\",\n    lead_time=1,\n    se_model_path=f\"{ddir}/trained_model/encoder\",\n    forecast_model_path=f\"{ddir}/trained_model/processor\",\n    sf_model_path=f\"{ddir}/trained_model/decoder/{local_forecast_var}/\",\n    return_gridded=True,\n    aux_data_path=f\"{ddir}/sample_data/\",\n)\n\nLoad the trained weights\n\nweights_path = f\"{ddir}/trained_model/e2e_finetuned/{local_forecast_var}/\"\nbest_epoch = np.argmin(np.load(weights_path+\"losses_0.npy\"))\nstate_dict = torch.load(\n    f\"{weights_path}/epoch_{best_epoch}\", map_location=\"cuda\",weights_only=False\n)[\"model_state_dict\"]\nstate_dict = {k[7:]: v for k, v in zip(state_dict.keys(), state_dict.values())}\nmodel.load_state_dict(state_dict)\nmodel = model.to(\"cuda\")\n\n\n#station_forecast = model(data)\nstation_forecast, global_forecast, initial_state = model(data)\n\nafter rMLP: torch.Size([1, 8719, 1])",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  },
  {
    "objectID": "Example-Notebooks/aardvark.html#visualise-model-predictions-1",
    "href": "Example-Notebooks/aardvark.html#visualise-model-predictions-1",
    "title": "Climate Weather AI/ML Model - Aardvark Weather",
    "section": "Visualise model predictions",
    "text": "Visualise model predictions\nPlot the station forecasts\n\nSTATION_LON_LAT_SF = 360\nHADISD_SCALING_FACTOR = 10\n# Factors to unnormalise predictions\nmean = np.load(f\"{ddir}/sample_data/norm_factors/mean_hadisd_{local_forecast_var}.npy\")\nstd = np.load(f\"{ddir}/sample_data/norm_factors/std_hadisd_{local_forecast_var}.npy\")\n\n\nstation_forecast_unnorm = (\n    station_forecast.detach().cpu() * std + mean\n) * HADISD_SCALING_FACTOR\n\n/jobfs/151106967.gadi-pbs/ipykernel_405681/444701172.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n  station_forecast.detach().cpu() * std + mean\n\n\n\nfig = plt.figure(figsize=(10, 5))\nplot_channel = 10\np = plt.scatter(\n    data[\"downscaling\"][\"x_target\"][0, 0, :].detach().cpu() * STATION_LON_LAT_SF,\n    data[\"downscaling\"][\"x_target\"][0, 1, :].detach().cpu() * STATION_LON_LAT_SF,\n    c=station_forecast_unnorm[0, :],\n    vmax=30,\n    vmin=-30,\n    cmap=\"RdBu_r\",\n)\ncbar = fig.colorbar(p)\ncbar.set_label(\"(C)\")\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(f\"{local_forecast_var}\")\nplt.show()",
    "crumbs": [
      "Example Notebooks",
      "Climate Weather AI/ML Model - Aardvark Weather"
    ]
  }
]